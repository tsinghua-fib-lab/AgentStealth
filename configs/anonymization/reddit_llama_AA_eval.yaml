output_dir: results
seed: 10
task: ANONYMIZED
dryrun: false
save_prompts: true
timeout: 0.0
task_config:
  run_eval_inference: true
  profile_path: anonymized_results/llama/eval_inference_results1.jsonl
  outpath: anonymized_results/llama
  anonymizer:
    anon_type: llm
    target_mode: single
    max_workers: 4

  anon_model:
    name: "llama3-8b-8192"
    provider: "openai_slm"
    args: {
      temperature: 0.1,
      url: "http://localhost:8000",
      attack_model: "llama3-8b-8192"
    }
  inference_model:
    name: "llama3-8b-8192"
    provider: "openai_slm"
    args: {
      temperature: 0.1,
      url: "http://localhost:8000"
    }
  utility_model:
    name: deepseek-ai/DeepSeek-V3
    provider: siliconflow
    args:
      temperature: 0.1
  eval_inference_model:
    name: deepseek-ai/DeepSeek-V3
    provider: siliconflow
    args:
      temperature: 0.1
  profile_filter:
    hardness: 1
    certainty: 1
    num_tokens: 1000
  max_num_iterations: 5
  use_ner: false
  offset: 0
  num_profiles: 500
gen_model:
  name: deepseek-ai/DeepSeek-V3
  provider: siliconflow
  args:
    temperature: 0.1
